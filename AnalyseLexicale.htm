<html>
	<head>
		<title>Analyse lexicale</title>
		<style>
SECTION { margin-left: 1em; }
CODE { background: #eee; }
.myNode {
	border:1px solid #CCC;
	display:inline-block;
	margin: 2px;
	padding: 2px;
	white-space: pre;
	}
.brut
	{ background: blue; }
.undefined
	{ background: yellow; }

.tab		{ background: LIGHTBLUE !important; }
.space		{ background: LIGHTGREEN !important; }
.linefeed	{ background: ORANGE !important; }
#eResult {
	display: inline;
	vertical-align: top;
	}

		</style>
	</head>
	<body>
<a href="index.htm">Index</a>

<h1>Analyse lexicale</h1>
<p>
	La machine réalisant cette tâche est nommée <b>lexer</b> dans cette application.<br>
	Autres noms possibles:  <i>scanneur</i>, <i>lexeur</i> ou <i>analyseur lexical</i>.
</p>

<h2>Préambule</h2><section>
	<p>
		Le lexer parcours un texte source caractère/caractère et le transforme en 
		<a href="Lexers.performance.readToken.htm">liste de lexèmes</a> .<br>
		Changer le texte ci-dessous :
	</p>
	<textarea id="eTextScanned" type="text">Le texte source.
	
	FIN.</textarea>
	<div id="eResult">...</div>
</section>
<h2>Principes</h2><section>
	<h3>Le lexème</h3><section>
		<ul>
			<li>il est défini par une <a href="src/regexp/syntax.htm">ER</a> ou un <a href="AFD.info.htm">AFD</a></li>
			<li>il est appelé token, bien qu'il soit une instance d'un token</li>
		</ul>
	</section>
	<h3>Fonctionnement</h3><section>
		<img src="img/scan.png">
		<p>La fonction <code>readToken</code> retourne par défaut le token suivant, voir <code>true</code> si un token est passé.</p>
		<p>
			Il est impératif que la règle d'analyse de base puisse identifier tous les tokens pouvant être trouvé, 
			sinon l'analyse risque d'être stoppé prématurément. <br>
			Pour cela il est possible d'utiliser un token nommé <code>NOT_WHITE_SPACES</code> détectant tout sauf un espace blanc. 
			Il suffit de l'ajouter en fin de règle et de surtout détecter tous les espaces blancs !
		</p>
	</section>
</section>

<h2>Contraintes</h2><section>
	<h3>Token précédant</h3><section>
		<p>
			En JavaScript il faut savoir différencier la division '/' au délimitation d'une expression régulière : <br>
			Pour cela, il nous faut connaître le token précédant.
			Si le token précédant correspond à token pouvant être avant le token trouvé alors celui-ci est validé. <br>
			Sinon il faut en trouver un autre !
		</p>
	</section>
	<h3>Passer des tokens</h3><section>
		<p>
			Il nous faut parfois obtenir une liste de lexème réduite en omettant certains tokens non significatifs.<br>
			Les commentaires en font partie, comme les espaces blancs... mais là, ce n'est pas forcément le cas (sauts de ligne en JavaScript).
		</p>
	</section>
</section>

<script src="js/framework.js"></script>
<script src="js/lexer.class.js"></script>
<script src="js/lexer.automaton.js"></script>
<script>
_('eTextScanned,eResult')
var setElementTitle =function(o){
	return  ' value:\u25B6'+o.value+'\u25C0\n'
		+ JSON.stringify( o, 'token,parentToken,css,index,lineStart,lineEnd'.split(','), " " )
			.str_replace('"', '')
			.slice(2,-1)
			.split(',')
			.join('')
	}
var Lexeme =function( o ){
	var sToken = o.token
	, e = document.createElement( sToken )
	, sValue = o.value
	e.oValue = o
	e.title = setElementTitle( o )
		// sToken +\n\u25B6+ sValue +\u25C0
	if( sValue ) e.innerHTML = sValue.str_replace( ['&','<','>'], ['&amp;','&lt;','&gt;'])
	e.className = 'myNode'
	if( o.css ) e.className += ' '+ o.css
	return e
	}
var scan =function(){
	eResult.innerHTML = ''
	eResult.appendChild( AutomatonLexer( eTextScanned.value, 'TXT' ))
	}
scan()
eTextScanned.onkeyup = scan
eTextScanned.focus()
</script>
	</body>
</html>