<html>
	<head>
		<title>Mes Lexers</title>
		<style>
SECTION { margin-left: 1em; }
UL {
	list-style-position: inside;
	padding: 0 1em;
	margin: 1em 0;
	}
LI {
	padding: 0 1em;
	}
.lexer {
	background: #EEE;
	border: 1px solid #666;
	float: left;
	list-style-type: none;
	margin: 0 .5em 2em;
	padding: .5em 1em;
	white-space: nowrap;
	}
H2, H3 {
	clear: left;
	}
		</style>
	</head>
	<body>
<a href="index.htm">Index</a>


<h1>Mes Lexers</h1>

<p>Il y a trois différents lexers créés et testés  :</p>
<ul>
	<li><a href="#MultiRegExpLexer">Lexer à une expression régulière par token</a></li>
	<li><a href="#OneRegExpLexer">Lexer à une expression régulière</a></li>
	<li><a href="#AutomatonLexer">Lexer à automates finis déterministes</a></li>
</ul>



<h2>Principe de fonctionnement</h2><section>
	<p>Il sont créés depuis une <a href="xml/fr/doc/LexerClass.xml">même base</a> :</p>
	<ul>
		<li>Parcours du texte une et une seule fois.</li>
		<li>Détection du début d'un token parent avec imbrication de token enfant.</li>
		<li>Détection de fin d'un token parent.</li>
		<li>Réalisation d'un double scannage d'un token (à éviter si possible!).</li>
		<li>Incrémentation de ligne courante.</li>
		<li>Utilisation d'une liste d'<i>objet</i> pour reconnaître des tokens.<br>
			<small><b>ATTENTION</b></small>: Premier objet arrivé, premier objet trouvé.
			<ol>
				<li>Un ordre est requis (mots clés avant identifiant, ...)</li>
				<li>Les objets trouvés le plus souvant doivent être classés en tête :
					<i>amélioration des performances</i>.</li>
			</ol>
		</li>
		<li><a href="Lexers.performance.scan.incremental.htm">Analyse partielle</a> suite à une modification.</li>
	</ul>
	<p>
		Ils réalisent une analyse à <a href="Lexers.result.comparaison.htm">plusieurs niveaux</a>: 
		un <i>arbre lexicale</i> est créé et non pas une liste.<br>
		Je reste persuader qu'il est possible de le modifier pour obtenir une liste, mon objectif étant de limiter la taille des listes d'enfant.
	</p>
	<p>Si vous recherchez un lexer retournant une liste de tokens, consultez le site d'Eli Bendersky, il pourra vous être utile :</p>
	<ul>
		<li><a target="_blank" href="http://eli.thegreenplace.net/2013/06/25/regex-based-lexical-analysis-in-python-and-javascript">Regex-based lexical analysis in Python and Javascript</a></li>
		<li><a target="_blank" href="http://eli.thegreenplace.net/2013/07/16/hand-written-lexer-in-javascript-compared-to-the-regex-based-ones">Hand-written lexer in Javascript compared to the regex-based ones </a></li>
	</ul>
</section>

<h2>Performance</h2><section>
	<p>Elle est mesurée sur deux méthodes :</p>
	<ul>
		<li><b>readToken</b>: <a href="Lexers.performance.readToken.htm">vitesse de lecture des tokens</a> pour un lexer.</li>
		<li><b>scan</b>: comparaison de la <a href="Lexers.performance.scan.htm">vitesse de lecture totale</a> des lexers.</li>
	</ul>
	<p>
		L'<a href="Lexers.result.comparaison.htm">équivalence des résultats</a> des analyses lexicales est comparée 
		afin d'assurer des mesures dans des conditions identiques.
	</p>
	<p>La performance est dependante de l'objet retourné par la fonction <a href="Lexeme.htm">Lexeme</a>.</p>
</section>

<h2>Observations</h2><section>
	<a name="AutomatonLexer"></a>
	<h3>Automaton Lexer</h3><section>
		Utilise des AFD : Il reconnaisse 1 à plusieurs tokens.
		<ul>
			<li style="color:orange;">Pas le plus rapide des lexer.</li>
			<li style="color:red;">Modules énormes et abstraits...</li>
			<li style="color:green;">Le plus long token trouvé est toujours retourné.</li>
			<li><strike>Analyse partielle implémenté (<a href="Lexers.performance.scan.incremental.htm">aperçu</a>).</strike></li>
		</ul>
		
		<h4>Considérations techniques</h4><section>
			<p>Les AFD doivent-être précalculés car leur calcul prend du temps.</p>
			<ol>
				<li>Chaque <a href="AFD.generator.htm">ER transformé en AFD</a></li>
				<li>Les <a href="AFD.aggregator.htm">AFD sont ensuite aggrégés entre eux</a> afin d'en obtenir plus qu'un !</li>
			</ol>
			<p>Malheureusement il est parfois préférable d'utiliser plusieurs AFD au lieu d'un :</p>
			<ul>
				<li>La taille de l'automate résultat pouvant-être trop volumineuse, </li>
				<li>ou sa création prennant beaucoup trop de temps.</li>
			</ul>
			<!-- <p>Vous pouvez <a href="LexerAutomaton.module.generator.htm">créer des modules pour le Lexer Automaton</a>.</p> -->
			<p>L'analyse lexicale se fait ensuite avec un ou plusieurs AFD :</p>
			<ul>
				<li>Performance (calcul) = 1 AFD.</li>
				<li>Maintenance / Evolution = Plusieurs AFDs.</li>
				<li>Performance téléchargement = Fonction de la taille des AFDs.</li>
			</ul>
		</section>
	</section>
	<a name="MultiRegExpLexer"></a>
	<h3>Multiple RegExp Lexer</h3><section>
		Utilise des ER : Elle reconnaisse 1 et 1 seul token.
		<ul>
			<li style="color:red;">Lexer le plus lent.</li>
			<li style="color:green;">Modules à taille modeste et compréhensibles...</li>
			<li style="color:red;">Premier token arrivé, premier servi.</li>
		</ul>
		
		<h4>Considérations techniques</h4><section>
			<ul>
				<li>L'ordre des ER est important.
					<ul>
						<li>Première arrivée, première trouvée !</li>
						<li>[performance] Les ER les plus souvant rencontrés doivent être montée dans les premières position.</li>
					</ul>
				</li>
			</ul>
		</section>
	</section>
	<a name="OneRegExpLexer"></a>
	<h3>One RegExp Lexer</h3><section>
		<ul>
			<li style="color:green;">Lexer le plus rapide.</li>
			<li style="color:green;">Modules à taille modeste et compréhensibles...</li>
			<li style="color:green;">Le plus long token trouvé est toujours retourné en premier.</li>
			<li style="color:green;">ou premier token arrivé, premier servi.</li>
		</ul>
		
		<h4>Considérations techniques</h4><section>
			<ul>
				<li>Une seule grande expression régulière est créée pour parcourir le texte.</li>
				<li>Le défaut: quand un mot est trouvé il faut déterminé son type. 
					Pour cela il faut réaliser une boucle !</li>
				<li>En JavaScript il faut savoir différencier la division '/' au délimitation d'une expression régulière : 
						pour cela, j'ai besoin de connaître le token précédant. <br>
					Si le token précédant correspond à token pouvant être avant le token trouvé alors celui-ci est validé. <br>
						...sinon il faut parcourir les ER utilisées pour créer la grande une par une... pour finalement déterminer un autre token.
						<ul>
							<li>L'ordre des ER est important.
								<ul>
									<li>Première arrivée, première trouvée !</li>
									<li>[performance] Les ER les plus souvant rencontrés doivent être montée dans les premières position.</li>
								</ul>
							</li>
						</ul>
				</li>
			</ul>
		</section>
	</section>
</section>

	</body>
</html>